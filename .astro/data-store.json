[["Map",1,2,9,10],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.1.2","content-config-digest","07b459027aa8e1c9","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://florentlamoureux.fr\",\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[]},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":\"shiki\",\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"responsiveImages\":false},\"legacy\":{\"collections\":false}}","blog",["Map",11,12,22,23],"ai-desktop-private-llm",{"id":11,"data":13,"body":17,"filePath":18,"digest":19,"legacyId":20,"deferredRender":21},{"title":14,"description":15,"pubDate":16},"Building a local and offline private desktop AI app using LLMs","Using Electron and self contained Ollama server",["Date","2024-05-07T07:00:00.000Z"],"\u003Cdiv class=\"dark:text-slate-300\">\n    \u003Cp class=\"mt-4\">\n        I've been very interested in building offline and private AI applications.\n    \u003C/p>\n    \u003Cp class=\"mt-4\">\n         If your computer can handle it, like most Apple laptops with M1 Pro and latest chips do, you can improve a lot of workflows. \n    \u003C/p>\n    \u003Cp class=\"mt-4\">\n        Even outside of work, I often need to organize personal files, such as documents, bills, or photos. The only reliable way today to be able to use automated organization tools is to use cloud services. Unfortunately, this means that you have to upload your files to a third-party service, which can be a privacy concern.\n    \u003C/p>\n\n    \u003Cdiv class=\"mt-4\">\n    \u003Ca target=\"_new\" href=\"https://github.com/flrent/ai-get-started-desktop-app\" class=\"font-bold py-2 px-4 text-flxorange sm:px-0\">\n    ![https://github.com/flrent/ai-get-started-desktop-app](https://raw.githubusercontent.com/flrent/ai-get-started-desktop-app/96554f34637fdd1e9cb2982072496a7c82e61d98/screenshots/screenshot.png)\n    \u003C/a>\n    \u003C/div>\n    \u003Cp class=\"mt-4\">\n        With a local LLM, a desktop app that can be written using Electron, you can have a private and offline AI application that can use an LLM as a agent for a very specific task. For instance, automatically classifying all your photos into categories based on portraits, cities they're taken in, or any other metadata that models like LLava or Moondream can find.\n    \u003C/p>\n    \u003Cp class=\"mt-4\">\n        You could also have your app connect to Messages.app or Photos Library, read the sqlite database, and build a search, insights features, or any other ideas on top of it leveraging AI.\n    \u003C/p>\n    \u003Cp class=\"mt-4\">\n        I was very excited when I found out \u003Ca target=\"_new\" href=\"https://www.chatd.ai/\">chatd\u003C/a> when I realized they bundled not only the client app, but the model and the inference server in a single app. This means you can run the server locally, pick any model that Ollama supports, and have a private and offline AI application. The only downside is that it's only as powerful as your machine, and that it needs to download GBs of models before doing anything.\n    \u003C/p>\n    \u003Cp class=\"mt-4\">\n        I'm now tinkering with this setup, and will likely experiment building single task-focused AI apps that can run locally. In the meantime, I've created a repo from the original chatd codebase as a blank boilerplate of this setup, with the bare minimum to get started. It contains what you need to interact with a model using Electron's APIs, the bundle logic, and a basic UI.\n    \u003C/p>\n    \u003Cdiv class=\"mt-4 flex justify-center sm:justify-start\">\n        \u003Ca target=\"_new\" href=\"https://github.com/flrent/ai-get-started-desktop-app\" class=\"font-bold py-2 px-4 text-flxorange sm:px-0\">\n            Check out flrent/ai-get-started-desktop-app on Github\n        \u003C/a>\n    \u003C/div>\n\n    \u003Cp class=\"mt-4\">Enjoy!\u003C/p>\n\n\u003C/div>","src/content/blog/ai-desktop-private-llm.mdx","2ce60159e62fb614","ai-desktop-private-llm.mdx",true,"twitter-threads-chrome-extension",{"id":22,"data":24,"body":28,"filePath":29,"digest":30,"legacyId":31,"deferredRender":21},{"title":25,"description":26,"pubDate":27},"Find Twitter users on threads.net","Browser extension to find twitter users on threads.net",["Date","2023-07-07T07:00:00.000Z"],"\u003Cdiv class=\"dark:text-slate-300\">\n    \u003Cp class=\"mt-4\">\n        If you've recently started using threads.net, you may encounter some challenges when trying to locate users you already follow on the platform, especially when using it on desktop.\n    \u003C/p>\n    \u003Cp class=\"mt-4\">\n        To address this issue, I've developed a simple browser extension for Chrome. This extension adds a convenient Threads emoji (ðŸ§µ) link to Twitter profiles, allowing you to effortlessly navigate to the corresponding @username on threads.net. From there, you can easily scan the QR code on your phone to start following that person. In case the user does not exist on threads.net, you will be redirected to a 404 page.\n    \u003C/p>\n    \u003Cp class=\"mt-4\">\n        Currently threads.net currently lacks a public search feature on the web. As soon as threads.net introduces a search functionality, I will enhance the extension to trigger a search. This should ensure that even if a user is using a different username, they can be found.\n    \u003C/p>\n    \u003Cp class=\"mt-4\">\n        You can give it a try there:\n    \u003C/p>\n    \u003Cdiv class=\"mt-4 flex justify-center sm:justify-start\">\n        \u003Ca target=\"_new\" href=\"https://chrome.google.com/webstore/detail/threadsnet-link-on-twitte/aeeglamcocigmdanplchcbjldjmokoid\" class=\"font-bold py-2 px-4 text-flxorange sm:px-0\">\n            Download the Chrome Extension Threads.net link on twitter pages\n        \u003C/a>\n    \u003C/div>\n\n    \u003Cdiv class=\"flex justify-center sm:justify-start\">\n        \u003Ca  target=\"_new\" href=\"https://github.com/flrent/chrome-twitter-threads\" class=\"font-bold py-2 px-4 text-flxorange sm:px-0\">\n        GitHub Repository\n        \u003C/a>\n    \u003C/div>\n\n    \u003Cdiv class=\"mt-4\">\n    ![](https://github.com/flrent/chrome-twitter-threads/raw/main/screenshot.png)\n    \u003C/div>\n\n    \u003Cp class=\"mt-4\">Enjoy!\u003C/p>\n\n\u003C/div>","src/content/blog/twitter-threads-chrome-extension.mdx","5ce09fbddef0d815","twitter-threads-chrome-extension.mdx"]